# 第一部分

###### 心得

###### 李洁：

###### 视频中提到，玻尔兹曼机和变分自编码器是目前最重要的概率生成式模型，变分自编码器是非监督生成模型，与对抗式生成网络GAN关系密切，是深度学习-概率图模型的桥梁。去噪自编码器能够提取鲁棒特征表达。深层网络的局部极小值主要是多个隐层复合导致的。矩阵的低秩近似是可以保留决定数据分布的最主要的方向。卷积神经网络的主要应用：分类、检索、检测、分割、人脸验证和识别、人脸表情识别、图像生成、图像风格转化、自动驾驶等。卷积神经网络典型结构：AlexNet,ZFNet,VGG,GoogleNet,ResNet.

###### 对于一些基本概念有了初步了解，并且大部分都能看懂，但是对于比如卷积神经网络它的运用方法，训练时模型所使用的过程，代码还没有完全掌握，个人感觉python相对来说比较难学一些，语法不太一样，函数以及库比较多一些。

###### 问题：AlexNet中DropOut那一步是怎么做到的？AlexNet分层解析没看太懂。（李洁）

# 第二部分

###### 李洁：

###### 代码练习及想法解读

![Alt text](E:/3.png)

###### 明明代码一样，咱也不知道为啥结果就不一样呢，我感觉是第一步文件下载出了问题，实在是不知道为啥了。

![Alt text](E:/1.png)

![Alt text](E:/2.png)

###### 这两张图片是用CIFAR10来进行数据分类，识别图片，输出的结果正确率只有一半。应该是样本数量太少，对于某些具体的特征不能分辨，或者因为某些图片的局部实在很相似。





